{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task4_Shchukhomet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RerCPo21KTCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPzj-2Q5uqNR",
        "colab_type": "text"
      },
      "source": [
        "let's solve the problem of unbalanced sampling by changing the input data to more dependent ones, as we did in the previous task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ma43rUkMrEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_samples = 1000\n",
        "X0 = np.random.normal(loc=[0,0], scale=[2,0.5], size=(int(n_samples/2), 2))\n",
        "X11 = np.random.normal(loc=[0,3.5], scale=[0.5,1], size=(int(n_samples/4), 2))\n",
        "X12 = np.random.normal(loc=[0,-3.5], scale=[0.5,1], size=(int(n_samples/4), 2))\n",
        "X1 = np.vstack([X11, X12])\n",
        "train_X = np.vstack([X0, X1]) # input array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6Ib8vUcNO7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y0 = np.zeros(shape=(int(n_samples/2), 1))\n",
        "y1 = np.ones(shape=(int(n_samples/2), 1))\n",
        "train_Y = np.vstack([y0, y1]) # output array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9eqWXnrvXAe",
        "colab_type": "text"
      },
      "source": [
        "and immediately test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOIZHwp6Pyu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_samples = 500\n",
        "X0 = np.random.normal(loc=[0,0], scale=[2,0.5], size=(int(n_samples/2), 2))\n",
        "X11 = np.random.normal(loc=[0,3.5], scale=[0.5,1], size=(int(n_samples/4), 2))\n",
        "X12 = np.random.normal(loc=[0,-3.5], scale=[0.5,1], size=(int(n_samples/4), 2))\n",
        "X1 = np.vstack([X11, X12])\n",
        "test_X = np.vstack([X0, X1]) # input array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ea7h8WkvjEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y0 = np.zeros(shape=(int(n_samples/2), 1))\n",
        "y1 = np.ones(shape=(int(n_samples/2), 1))\n",
        "test_Y = np.vstack([y0, y1]) # output array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1RvOFPfQXRk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "058edf3c-8132-4d98-ab49-0ab1e82d0f22"
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras import layers"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp_wlE6mRAMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the architecture of the neural network. 3 neurons in the hidden layer, 1 in the output. activation functions for each layer too\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(3, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zY9LbE5SM6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we set the network training parameters: optimizer, error function, and metric by which we will evaluate the result\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fesdmXBtdOWb",
        "colab_type": "code",
        "outputId": "f11a0451-d35d-49f1-dd51-a2ff3da1f990",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# and train it\n",
        "model.fit(train_X, train_Y, epochs=100, batch_size=32)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 0s 310us/step - loss: 1.5729 - accuracy: 0.4890\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 1.4307 - accuracy: 0.4650\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 0s 32us/step - loss: 1.3045 - accuracy: 0.4420\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 1.1841 - accuracy: 0.4210\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 0s 41us/step - loss: 1.0757 - accuracy: 0.4080\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 0s 37us/step - loss: 0.9752 - accuracy: 0.3870\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 0s 38us/step - loss: 0.8869 - accuracy: 0.3790\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.8120 - accuracy: 0.3840\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.7465 - accuracy: 0.4360\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.6912 - accuracy: 0.5050\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.6479 - accuracy: 0.5550\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.6122 - accuracy: 0.5760\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.5835 - accuracy: 0.5850\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.5587 - accuracy: 0.5980\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.5376 - accuracy: 0.6100\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.5186 - accuracy: 0.6340\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.5023 - accuracy: 0.6490\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.4875 - accuracy: 0.6640\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.4740 - accuracy: 0.6840\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 0s 32us/step - loss: 0.4615 - accuracy: 0.6960\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 0s 36us/step - loss: 0.4501 - accuracy: 0.7160\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.4388 - accuracy: 0.7280\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.4282 - accuracy: 0.7450\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.4184 - accuracy: 0.7560\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.4094 - accuracy: 0.7670\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.4005 - accuracy: 0.7850\n",
            "Epoch 27/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.3919 - accuracy: 0.8030\n",
            "Epoch 28/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.3837 - accuracy: 0.8130\n",
            "Epoch 29/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.3756 - accuracy: 0.8190\n",
            "Epoch 30/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.3681 - accuracy: 0.8270\n",
            "Epoch 31/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.3611 - accuracy: 0.8360\n",
            "Epoch 32/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.3539 - accuracy: 0.8480\n",
            "Epoch 33/100\n",
            "1000/1000 [==============================] - 0s 39us/step - loss: 0.3467 - accuracy: 0.8590\n",
            "Epoch 34/100\n",
            "1000/1000 [==============================] - 0s 38us/step - loss: 0.3400 - accuracy: 0.8660\n",
            "Epoch 35/100\n",
            "1000/1000 [==============================] - 0s 38us/step - loss: 0.3335 - accuracy: 0.8700\n",
            "Epoch 36/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.3272 - accuracy: 0.8730\n",
            "Epoch 37/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.3211 - accuracy: 0.8790\n",
            "Epoch 38/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.3153 - accuracy: 0.8860\n",
            "Epoch 39/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.3097 - accuracy: 0.8950\n",
            "Epoch 40/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.3044 - accuracy: 0.8970\n",
            "Epoch 41/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.2991 - accuracy: 0.9020\n",
            "Epoch 42/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.2941 - accuracy: 0.9080\n",
            "Epoch 43/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.2891 - accuracy: 0.9130\n",
            "Epoch 44/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.2843 - accuracy: 0.9170\n",
            "Epoch 45/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.2796 - accuracy: 0.9220\n",
            "Epoch 46/100\n",
            "1000/1000 [==============================] - 0s 38us/step - loss: 0.2753 - accuracy: 0.9230\n",
            "Epoch 47/100\n",
            "1000/1000 [==============================] - 0s 36us/step - loss: 0.2712 - accuracy: 0.9270\n",
            "Epoch 48/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.2672 - accuracy: 0.9290\n",
            "Epoch 49/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.2629 - accuracy: 0.9320\n",
            "Epoch 50/100\n",
            "1000/1000 [==============================] - 0s 32us/step - loss: 0.2587 - accuracy: 0.9370\n",
            "Epoch 51/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.2547 - accuracy: 0.9390\n",
            "Epoch 52/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.2506 - accuracy: 0.9390\n",
            "Epoch 53/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.2468 - accuracy: 0.9390\n",
            "Epoch 54/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.2429 - accuracy: 0.9380\n",
            "Epoch 55/100\n",
            "1000/1000 [==============================] - 0s 36us/step - loss: 0.2389 - accuracy: 0.9390\n",
            "Epoch 56/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.2353 - accuracy: 0.9410\n",
            "Epoch 57/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.2317 - accuracy: 0.9430\n",
            "Epoch 58/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.2283 - accuracy: 0.9450\n",
            "Epoch 59/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.2251 - accuracy: 0.9450\n",
            "Epoch 60/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.2218 - accuracy: 0.9450\n",
            "Epoch 61/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.2185 - accuracy: 0.9480\n",
            "Epoch 62/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.2151 - accuracy: 0.9480\n",
            "Epoch 63/100\n",
            "1000/1000 [==============================] - 0s 38us/step - loss: 0.2121 - accuracy: 0.9490\n",
            "Epoch 64/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.2091 - accuracy: 0.9520\n",
            "Epoch 65/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.2060 - accuracy: 0.9550\n",
            "Epoch 66/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.2028 - accuracy: 0.9540\n",
            "Epoch 67/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.1995 - accuracy: 0.9550\n",
            "Epoch 68/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.1966 - accuracy: 0.9570\n",
            "Epoch 69/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.1939 - accuracy: 0.9580\n",
            "Epoch 70/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.1912 - accuracy: 0.9590\n",
            "Epoch 71/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.1883 - accuracy: 0.9600\n",
            "Epoch 72/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.1856 - accuracy: 0.9600\n",
            "Epoch 73/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.1828 - accuracy: 0.9600\n",
            "Epoch 74/100\n",
            "1000/1000 [==============================] - 0s 37us/step - loss: 0.1800 - accuracy: 0.9600\n",
            "Epoch 75/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.1772 - accuracy: 0.9600\n",
            "Epoch 76/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.1744 - accuracy: 0.9610\n",
            "Epoch 77/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.1717 - accuracy: 0.9620\n",
            "Epoch 78/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.1691 - accuracy: 0.9620\n",
            "Epoch 79/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.1665 - accuracy: 0.9630\n",
            "Epoch 80/100\n",
            "1000/1000 [==============================] - 0s 36us/step - loss: 0.1639 - accuracy: 0.9610\n",
            "Epoch 81/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.1612 - accuracy: 0.9630\n",
            "Epoch 82/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.1588 - accuracy: 0.9630\n",
            "Epoch 83/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.1565 - accuracy: 0.9650\n",
            "Epoch 84/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.1544 - accuracy: 0.9650\n",
            "Epoch 85/100\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.1522 - accuracy: 0.9660\n",
            "Epoch 86/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.1501 - accuracy: 0.9670\n",
            "Epoch 87/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.1480 - accuracy: 0.9690\n",
            "Epoch 88/100\n",
            "1000/1000 [==============================] - 0s 40us/step - loss: 0.1458 - accuracy: 0.9690\n",
            "Epoch 89/100\n",
            "1000/1000 [==============================] - 0s 39us/step - loss: 0.1438 - accuracy: 0.9690\n",
            "Epoch 90/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.1418 - accuracy: 0.9690\n",
            "Epoch 91/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.1397 - accuracy: 0.9690\n",
            "Epoch 92/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.1377 - accuracy: 0.9700\n",
            "Epoch 93/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.1357 - accuracy: 0.9730\n",
            "Epoch 94/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.1335 - accuracy: 0.9730\n",
            "Epoch 95/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.1315 - accuracy: 0.9740\n",
            "Epoch 96/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.1296 - accuracy: 0.9740\n",
            "Epoch 97/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.1276 - accuracy: 0.9740\n",
            "Epoch 98/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.1257 - accuracy: 0.9730\n",
            "Epoch 99/100\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.1240 - accuracy: 0.9740\n",
            "Epoch 100/100\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.1222 - accuracy: 0.9740\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f235ee68438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loQYjgQw2kfy",
        "colab_type": "code",
        "outputId": "b2ccb11b-ffb5-4b93-a0e0-5b6f01f24de7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# test our network with test data\n",
        "test_loss, test_acc = model.evaluate(test_X, test_Y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - 0s 57us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQKmIm8G4Cnj",
        "colab_type": "code",
        "outputId": "f23e03dc-77e2-4185-8c4a-17add7d6c113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('test_acc:', test_acc)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_acc: 0.9819999933242798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "povz0IsMwc__",
        "colab_type": "text"
      },
      "source": [
        "the accuracy was 98.1% in contrast to the third task, in which 98.6% was obtained. in truth, the keras model should have gotten better accuracy than numpy thanks to the algorithms already implemented. but since we took randomly generated data arrays, there could be an error. but in general both models showed themselves very well for solving this problem"
      ]
    }
  ]
}